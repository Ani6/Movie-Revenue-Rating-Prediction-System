{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fundamentals of Data Science Project\n",
    "# Part created by Anjana Tiha:\n",
    "\n",
    "# Features:\n",
    "# Numerical Features: actor1 Facebook likes, actor2 Facebook likes, actor3 Facebook likes, director Facebook likes, budget.\n",
    "# Text Features(converted to categorical data): actor1 name, actor2 name, actor3 name, director name, country, content rating, language\n",
    "\n",
    "# Preprocessing-\n",
    "#  Text Features:\n",
    "#    - Text data like top 3 actor names, director names, content rating, country and language have been treated as category \n",
    "#    - categorical data has been labelized and binarized for each feature column (each item in a feature column has unique label and binary form)\n",
    "#  Numerical Features:\n",
    "#    - numerical data have been min max scaled by fitting to minmaxscaler  \n",
    "#    - rows with missing gross value and any empty major features have been eliminated\n",
    "#    - preprocessed numerical, categorical data and text data especially for gross prediction with categorical data in mind\n",
    "\n",
    "# Both numerical and text data has been used for gross prediction/regression.\n",
    "\n",
    "# Regression Model: Random forest Regression and Decision Tree Regression.\n",
    "# Other models tried: SVR\n",
    "\n",
    "# Evaluation:\n",
    "#    - 5-Fold Cross Validation\n",
    "#    - Evaluation Metrics: Mean Absolute Error, Mean Squared Error, Median Absolute Error\n",
    "#    - Others tried: Explained Var Score, R^2 score have been calculated\n",
    "# Visualization: \n",
    "#    - actor1, actor2, actor3, director, country, content rating, language by mean gross have been visualized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, explained_variance_score, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global minval\n",
    "global maxval\n",
    "global min_max_scaler\n",
    "global catagory_features\n",
    "global number_features\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "text_features = ['genre', 'plot_keywords', 'movie_title']\n",
    "catagory_features = ['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name', 'country', 'content_rating', 'language']\n",
    "number_features = ['actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'director_facebook_likes','cast_total_facebook_likes','budget', 'gross']\n",
    "all_selected_features = ['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name', 'country', 'content_rating', 'language', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'director_facebook_likes','cast_total_facebook_likes','budget', 'gross', 'genres']\n",
    "eliminate_if_empty_list = ['actor_1_name', 'actor_2_name', 'director_name', 'country', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'director_facebook_likes','cast_total_facebook_likes', 'gross']\n",
    "\n",
    "#preprocessing\n",
    "def data_clean(path):\n",
    "    read_data = pd.read_csv(path)\n",
    "    select_data = read_data[all_selected_features]\n",
    "    data = select_data.dropna(axis = 0, how = 'any', subset = eliminate_if_empty_list)\n",
    "    data = data.reset_index(drop = True)\n",
    "    for x in catagory_features:\n",
    "        data[x] = data[x].fillna('None').astype('category')\n",
    "    for y in number_features:\n",
    "        data[y] = data[y].fillna(0.0).astype(np.float)\n",
    "    return data\n",
    "\n",
    "def preprocessing_numerical_minmax(data):\n",
    "    global min_max_scaler\n",
    "    scaled_data = min_max_scaler.fit_transform(data)\n",
    "    return scaled_data\n",
    "    \n",
    "def preprocessing_categorical(data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoded_data = label_encoder.fit_transform(data) \n",
    "    label_binarizer = preprocessing.LabelBinarizer()\n",
    "    label_binarized_data = label_binarizer.fit_transform(label_encoded_data) \n",
    "    return label_binarized_data\n",
    "\n",
    "def preprocessing_text(data):  \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorized_text = tfidf_vectorizer.fit_transform(data)  \n",
    "    return tfidf_vectorized_text\n",
    "\n",
    "#regression model training\n",
    "def regression_without_cross_validation(model, train_data, train_target, test_data): \n",
    "    model.fit(train_data, train_target)\n",
    "    prediction = model.predict(test_data)\n",
    "    return prediction\n",
    "\n",
    "def regression_with_cross_validation(model, data, target, n_fold, model_name):\n",
    "    print(\"Regression Model Name: \", model_name)\n",
    "    cross_val_score_mean_abs_err  = cross_val_score(model, data, target, scoring = 'mean_absolute_error', cv = n_fold) \n",
    "    print(\"\\nCross Validation Score (Mean Absolute Error)        : \\n\", -cross_val_score_mean_abs_err)\n",
    "    print(\"\\nCross Validation Score (Mean Absolute Error) (Mean) : \\n\", -cross_val_score_mean_abs_err.mean())\n",
    "    cross_val_score_mean_sqr_err  = cross_val_score(model, data, target, scoring = 'mean_squared_error', cv = n_fold)  \n",
    "    print(\"\\nCross Validation Score (Mean Squared Error)         : \\n\", -cross_val_score_mean_sqr_err)\n",
    "    print(\"\\nCross Validation Score (Mean Squared Error)  (Mean) : \\n\", -cross_val_score_mean_sqr_err.mean())\n",
    "    \n",
    "def regression_scores(original_val, predicted_val, model_name):\n",
    "    print(\"Regression Model Name: \", model_name)\n",
    "    mean_abs_error = mean_absolute_error(original_val, predicted_val) \n",
    "    mean_sqr_error = mean_squared_error(original_val, predicted_val)\n",
    "    median_abs_error = median_absolute_error(original_val, predicted_val)\n",
    "    explained_var_score = explained_variance_score(original_val, predicted_val)\n",
    "    r2__score = r2_score(original_val, predicted_val)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"\\nRegression Scores(train_test_split):\\n\")\n",
    "    print(\"Mean Absolute Error    :\", mean_abs_error)\n",
    "    print(\"Mean Squared Error     :\", mean_sqr_error)\n",
    "    print(\"Median Absolute Error  :\", median_abs_error)\n",
    "    print(\"Explained Var Score    :\", explained_var_score)\n",
    "    print(\"R^2 Score              :\", r2__score)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "#simple task    \n",
    "def inverse_scaling(scaled_val):\n",
    "    unscaled_val = min_max_scaler.inverse_transform(scaled_val)\n",
    "    return unscaled_val\n",
    "\n",
    "def roundval(value):  \n",
    "    return value.round()\n",
    "\n",
    "def to_millions(value):   \n",
    "    return value / 10000000\n",
    "\n",
    "#evaluation    \n",
    "#plotting actual vs predicted for all data\n",
    "def prediction_performance_plot(original_val, predicted_val, model_name, start, end, n, plot_type):\n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    print(\"\\n\")\n",
    "    plt.title(\"\\nUsing Categorical and Numerical Features\\n\" + model_name + \": Actual Gross VS Predicted Gross(All Data)- \\n\")\n",
    "    if plot_type==\"all\":\n",
    "        plt.plot(original_val, c = 'g', label = \"Actual\")\n",
    "        plt.plot(predicted_val, c = 'b', label = \"Prediction\")\n",
    "    if plot_type==\"seq\":\n",
    "        plt.plot(original_val[start : end + 1], c = 'g', label = \"Actual\")\n",
    "        plt.plot(predicted_val[start : end + 1], c = 'b', label = \"Prediction\")\n",
    "    if plot_type==\"random\":\n",
    "        original_val_list = []\n",
    "        predicted_val_list = []\n",
    "        for k in range(n):\n",
    "            i = random.randint(0, len(predicted_val) - 1)\n",
    "            original_val_list.append(original_val[i])\n",
    "            predicted_val_list.append(predicted_val[i])\n",
    "        plt.plot(original_val_list, c = 'g', label = \"Actual\")\n",
    "        plt.plot(predicted_val_list, c = 'b', label = \"Prediction\")\n",
    "    plt.legend([\"Actual Gross\", \"Predicted Gross\"], loc = 'center left', bbox_to_anchor = (1, 0.8))\n",
    "    plt.ylabel('Gross (In Millions)', fontsize = 14)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#printing actual vs predicted in a range \n",
    "def print_original_vs_predicted_seq(original_val, predicted_val, i, j, model_name):\n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    \n",
    "    print(\"\\n\" , model_name, \": Comparision of Actual Gross VS Predicted Gross(Sequentional Sampling)\\n\")\n",
    "    if j<len(predicted_val):\n",
    "        for k in range(i, j + 1):\n",
    "            print(\"Actual Gross: \", original_val[k], \",   Predicted Gross: \", predicted_val[k])\n",
    "\n",
    "            \n",
    "#printing actual vs predicted in a randomly           \n",
    "def print_original_vs_predicted_rand(original_val, predicted_val, n, model_name):  \n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    print(\"\\n\" , model_name , \" : Comparision of Actual Gross VS Predicted Gross(Random Sampling)[In Millions]\\n\")\n",
    "    for k in range(n):\n",
    "        i = random.randint(0, len(predicted_val) - 1)\n",
    "        print(\"Actual Gross: \", original_val[i], \",   Predicted Gross: \", predicted_val[i])\n",
    "\n",
    "        \n",
    "#plotting actual vs predicted in a randomly using a bar chart          \n",
    "def bar_plot_original_vs_predicted_rand(original_val, predicted_val, n, model_name):  \n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    original_val_list = []\n",
    "    predicted_val_list = []\n",
    "    for k in range(n):\n",
    "        i = random.randint(0, len(predicted_val) - 1)\n",
    "        original_val_list.append(original_val[i])\n",
    "        predicted_val_list.append(predicted_val[i])\n",
    "    \n",
    "    original_val_df = pd.DataFrame(original_val_list)\n",
    "    predicted_val_df = pd.DataFrame(predicted_val_list)\n",
    "    \n",
    "    actual_vs_predicted = pd.concat([original_val_df, predicted_val_df], axis = 1)\n",
    "    \n",
    "    actual_vs_predicted.plot(kind = \"bar\", fontsize = 12, color = ['g','b'], width= 0.7)\n",
    "    plt.title(\"\\nUsing Categorical and Numerical Features\\n\" + model_name + \" : Actual Gross VS Predicted Gross(Random)\")\n",
    "    plt.ylabel('Gross (In Millions)', fontsize = 14)\n",
    "    plt.ylabel('Gross (In M', fontsize = 14)\n",
    "    plt.xticks([])\n",
    "    plt.legend([\"Actual Gross \", \"Predicted Gross\"], loc = 'center left', bbox_to_anchor = (1, 0.8))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "        \n",
    "#Plot features\n",
    "#calculate mean\n",
    "def meanbyfeature(data, feature_name, meanby_feature):\n",
    "    mean_data = data.groupby(feature_name).mean()\n",
    "    mean = mean_data[meanby_feature]\n",
    "    mean_sort = mean.sort(meanby_feature, inplace = False, ascending = False)\n",
    "    return mean_sort\n",
    "    \n",
    "def plot(data, kind, title, n_rows):\n",
    "    plt.title(title, fontsize = 15)\n",
    "    data[:n_rows].plot(kind = kind)\n",
    "    plt.show()\n",
    "    \n",
    "def show_features(database):\n",
    "    print(\"\\n\",\"--------------------------------------------------------------------------------------------------------\")\n",
    "    database.info()\n",
    "    print(\"\\n\",\"--------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing_catagory(data):\n",
    "    data_c=0\n",
    "    for i in range(len(catagory_features)):\n",
    "        new_data = data[catagory_features[i]]\n",
    "        new_data_c = preprocessing_categorical(new_data)\n",
    "        if i == 0:\n",
    "            data_c=new_data_c\n",
    "        else:\n",
    "            data_c = np.append(data_c, new_data_c, 1)\n",
    "    return data_c\n",
    "\n",
    "def preprocessing_numerical(data):\n",
    "    data_list_numerical = list(zip(data['director_facebook_likes'], data['actor_1_facebook_likes'], \n",
    "                                   data['actor_2_facebook_likes'], data['actor_3_facebook_likes'], \n",
    "                                   data['cast_total_facebook_likes'], data['budget']))\n",
    "\n",
    "    data_numerical = np.array(data_list_numerical)\n",
    "    data_numerical = preprocessing_numerical_minmax(data_numerical)\n",
    "    return data_numerical\n",
    "\n",
    "def preprocessed_agregated_data(database): \n",
    "    numerical_data = preprocessing_numerical(database)\n",
    "    categorical_data = preprocessing_catagory(database)\n",
    "    all_data = np.append(numerical_data, categorical_data, 1)\n",
    "    return all_data\n",
    "\n",
    "def regr_without_cross_validation_train_test_perform_plot(model, data, target, model_name):\n",
    "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size = 0.3, random_state = 0) \n",
    "    predicted_gross = regression_without_cross_validation(model, train_data, train_target, test_data)\n",
    "    regression_scores(test_target, predicted_gross, model_name)\n",
    "    #prediction_performance_plot(test_target, predicted_gross, model_name, 0, 0, 0, \"all\")\n",
    "    prediction_performance_plot(test_target, predicted_gross, model_name, 200, 250, 0, \"seq\")\n",
    "    prediction_performance_plot(test_target, predicted_gross, model_name, 0, 0, 100, \"random\")\n",
    "    print_original_vs_predicted_rand(test_target, predicted_gross, 10, model_name)\n",
    "    bar_plot_original_vs_predicted_rand(test_target, predicted_gross, 20, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anjana\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\Anjana\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Model Name:  Random Forest Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anjana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:90: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Anjana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:90: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Anjana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:90: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Anjana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:90: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Anjana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:90: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validation Score (Mean Absolute Error)        : \n",
      " [ 0.08526261  0.03942836  0.034679    0.02630681  0.01924687]\n",
      "\n",
      "Cross Validation Score (Mean Absolute Error) (Mean) : \n",
      " 0.0409847293608\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"movie_metadata.csv\"\n",
    "data = data=data_clean(path)\n",
    "#data = data[(data.actor_1_facebook_likes > 0.0) & (data.actor_2_facebook_likes > 0.0) & (data.actor_3_facebook_likes > 0.0) & (data.director_facebook_likes > 0.0) & (data.cast_total_facebook_likes > 0.0) & (data.gross > 0.0)]\n",
    "target = data['gross']\n",
    "database = data.drop('gross', 1)\n",
    "preprocessed_data = preprocessed_agregated_data(database)\n",
    "target = preprocessing_numerical_minmax(target)\n",
    "#print(\"_______________________________________________Random Forest Regressor Model_________________________________________\")\n",
    "randomForestRegressorModel = RandomForestRegressor()\n",
    "regression_with_cross_validation(randomForestRegressorModel, preprocessed_data, target, 5, \"Random Forest Regression\")\n",
    "regr_without_cross_validation_train_test_perform_plot(randomForestRegressorModel, preprocessed_data, target,\"Random Forest Regression\")\n",
    "#print(\"_____________________________________________________________________________________________________________________\")\n",
    "#print(\"_____________________________________________________________________________________________________________________\")\n",
    "#print(\"_______________________________________________Decision Tree Regressor Model_________________________________________\")\n",
    "#print(\"\")\n",
    "DecisionTreeRegressorModel = tree.DecisionTreeRegressor()\n",
    "regression_with_cross_validation(DecisionTreeRegressorModel, preprocessed_data, target, 5, \"Decision Tree Regression\")\n",
    "regr_without_cross_validation_train_test_perform_plot(DecisionTreeRegressorModel, preprocessed_data, target, \"Decision Tree Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "actor_1_gross_mean_sort = meanbyfeature(data, 'actor_1_name', 'gross')\n",
    "plot(actor_1_gross_mean_sort, 'bar', 'Actor 1 Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "actor_2_gross_mean_sort = meanbyfeature(data, 'actor_2_name', 'gross')\n",
    "plot(actor_2_gross_mean_sort, 'bar', 'Actor 2 Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "actor_3_gross_mean_sort = meanbyfeature(data, 'actor_3_name', 'gross')\n",
    "plot(actor_3_gross_mean_sort, 'bar', 'Actor 3 Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "director_gross_sort = meanbyfeature(data, 'director_name', 'gross')\n",
    "plot(director_gross_sort, 'bar', 'Director sorted by mean gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "country_gross_sort = meanbyfeature(data, 'country', 'gross')\n",
    "plot(country_gross_sort, 'bar', 'Country sorted by mean gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "content_rating_gross_sort = meanbyfeature(data, 'content_rating', 'gross')\n",
    "plot(content_rating_gross_sort, 'bar', 'Content Rating Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "c = plt.matshow(corr)\n",
    "plt.colorbar(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
